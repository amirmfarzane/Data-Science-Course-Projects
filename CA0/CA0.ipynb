{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ecfbb4b0c704e67",
      "metadata": {
        "id": "2ecfbb4b0c704e67"
      },
      "source": [
        "# Web Scraping and Introductory Data Analysis\n",
        "\n",
        "Welcome to Homework 0, where we will delve into web scraping and perform an introductory data analysis. This homework will be a hands-on exercise that will help you become familiar with the process of extracting data from websites and conducting basic statistical analysis.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "By the end of this homework, you will be able to:\n",
        "\n",
        "1. Set up a Python environment with the necessary libraries for web scraping and data analysis.\n",
        "2. Write a web scraping script using Beautiful Soup and Selenium to collect data from a website.\n",
        "3. Sample from the collected dataset and compare the statistics of the sample and the population.\n",
        "   \n",
        "## Tasks\n",
        "\n",
        "1. **Environment Setup**: Install the required libraries such as Beautiful Soup, Selenium, pandas, numpy, matplotlib, and seaborn.\n",
        "\n",
        "2. **Web Scraping**: Write a script to scrape transaction data from [Etherscan.io](https://etherscan.io/txs). Use Selenium to interact with the website and Beautiful Soup to parse the HTML content.\n",
        "\n",
        "3. **Data Sampling**: Once the data is collected, create a sample from the dataset. Compare the sample statistics (mean and standard deviation) with the population statistics.\n",
        "\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "1. A Jupyter notebook with all the code and explanations.\n",
        "2. A detailed report on the findings, including the comparison of sample and population statistics.\n",
        "Note: You can include the report in your notebook.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Begin by setting up your Python environment and installing the necessary libraries. Then, proceed with the web scraping task, ensuring that you handle any potential issues such as rate limiting. Once you have the data, move on to the data sampling and statistical analysis tasks.\n",
        "\n",
        "Remember to document your process and findings in the Jupyter notebook, and to include visualizations where appropriate to illustrate your results. <br>\n",
        "Good luck, and happy scraping!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca352a49724d191",
      "metadata": {
        "id": "1ca352a49724d191"
      },
      "source": [
        "## Data Collection (Etherscan)\n",
        "\n",
        "In this section, we will use web scraping to gather transaction data from the Ethereum blockchain using the Etherscan block explorer. Our objective is to collect transactions from the **last 10 blocks** on Ethereum.\n",
        "\n",
        "To accomplish this task, we will employ web scraping techniques to extract the transaction data from the Etherscan website. The URL we will be targeting for our data collection is:\n",
        "\n",
        "[https://etherscan.io/txs](https://etherscan.io/txs)\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. **Navigate to the URL**: Use Selenium to open the Etherscan transactions page in a browser.\n",
        "\n",
        "2. **Locate the Transaction Data**: Identify the HTML elements that contain the transaction data for the specified block range.\n",
        "\n",
        "3. **Extract the Data**: Write a script to extract the transaction details e.g. Hash, Method, Block, etc.\n",
        "\n",
        "4. **Handle Pagination**: If the transactions span multiple pages, implement pagination handling to navigate through the pages and collect all relevant transaction data.\n",
        "\n",
        "5. **Store the Data**: Save the extracted transaction data into a structured format, such as a CSV file or a pandas DataFrame, for further analysis.\n",
        "\n",
        "### Considerations\n",
        "\n",
        "- **Rate Limiting**: Be mindful of the website's rate limits to avoid being blocked. Implement delays between requests if necessary.\n",
        "- **Dynamic Content**: The Etherscan website may load content dynamically. Ensure that Selenium waits for the necessary elements to load before attempting to scrape the data.\n",
        "- **Data Cleaning**: After extraction, clean the data to remove any inconsistencies or errors that may have occurred during the scraping process.\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
        "- [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
        "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
        "- [Ethereum](https://ethereum.org/en/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC44BrUaa8-Y",
        "outputId": "b9c9fe1f-7326-455e-b9b0-f39844c2086c"
      },
      "id": "EC44BrUaa8-Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.18.1 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54fa10db-ec9e-4921-870a-50066926ed2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "54fa10db-ec9e-4921-870a-50066926ed2d",
        "outputId": "5a995e74-bfa3-4fd0-8cbe-43f0d4f0f241"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'webdriver_manager'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9070a8cc0886>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchrome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwebdriver_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchrome\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import json\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium.webdriver.common.keys import Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2232f9",
      "metadata": {
        "id": "ea2232f9",
        "outputId": "f5ae1c2b-bdcf-40de-c951-031bb6a51656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Hash               Method  \\\n",
            "0  0xfe2d690b99d54fd95ec62878169fa1bcf2162f4de09c...      Sell To Uniswap   \n",
            "1  0xe33896e4a5bafa442b90f0d7235bf42380ba62ff1f82...      Sell To Uniswap   \n",
            "2  0xe3064529e5983ca98f9898636c5ec81f9f68bf3b195c...      Sell To Uniswap   \n",
            "3  0xc9c806e8554527c51796db3cf814c7a8584ca04b75fe...              Approve   \n",
            "4  0x5b9815d0ac6885b604b69a37f15d0f4746d187c22c03...  Multiplex Multi ...   \n",
            "\n",
            "      Block                  Age        From To                   Value  \\\n",
            "0  19356643  2024-03-03 19:11:59  1709493119         0x: Exchange Proxy   \n",
            "1  19356643  2024-03-03 19:11:59  1709493119         0x: Exchange Proxy   \n",
            "2  19356643  2024-03-03 19:11:59  1709493119         0x: Exchange Proxy   \n",
            "3  19356643  2024-03-03 19:11:59  1709493119     PulsePad: PLSPAD Token   \n",
            "4  19356643  2024-03-03 19:11:59  1709493119         0x: Exchange Proxy   \n",
            "\n",
            "            TxnFee  \n",
            "0  0.014403182 ETH  \n",
            "1  0.018443724 ETH  \n",
            "2  1.352960825 ETH  \n",
            "3            0 ETH  \n",
            "4            0 ETH  \n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_data():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "\n",
        "    # Open Etherscan\n",
        "    driver.get(\"https://etherscan.io/blocks\")\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "    table = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'table')))\n",
        "\n",
        "\n",
        "    # Use BeautifulSoup to parse block numbers\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    blocks = [row.find('a').text for row in soup.find_all('tr')[1:11]]  # Get the last 10 blocks\n",
        "\n",
        "    transactions_data = []\n",
        "\n",
        "    # Iterate over blocks\n",
        "    # extract transactions\n",
        "    for block in blocks:\n",
        "        driver.get(f\"https://etherscan.io/txs?block={block}\")\n",
        "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'table-hover')))\n",
        "\n",
        "        # iterate over pagination\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        pagination = soup.find('ul', class_='pagination')\n",
        "        pages = 1\n",
        "        if pagination:\n",
        "            pages = len(pagination.find_all('li')) - 2  # Adjust for 'previous' and 'next' buttons\n",
        "\n",
        "        for page in range(1, pages + 1):\n",
        "            if page > 1:\n",
        "                # Go directly to the page\n",
        "                driver.get(f\"https://etherscan.io/txs?block={block}&p={page}\")\n",
        "                wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'table-hover')))\n",
        "\n",
        "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "            transactions_table = soup.find('table', class_='table-hover')\n",
        "\n",
        "            # Extract transactions\n",
        "            for row in transactions_table.find('tbody').find_all('tr'):\n",
        "                cells = row.find_all('td')\n",
        "                if len(cells) > 1:  # Ensure it's not an empty row\n",
        "                    transaction = {\n",
        "                        'Hash': cells[1].text.strip(),\n",
        "                        'Method': cells[2].text.strip(),\n",
        "                        'Block': block,\n",
        "                        'Age': cells[4].text.strip(),\n",
        "                        'From': cells[6].text.strip(),\n",
        "                        'To': cells[8].text.strip(),\n",
        "                        'Value': cells[9].text.strip(),\n",
        "                        'TxnFee': cells[10].text.strip(),\n",
        "                    }\n",
        "                    transactions_data.append(transaction)\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "    # Convert the list of dictionaries into a DataFrame and save as CSV\n",
        "    df = pd.DataFrame(transactions_data)\n",
        "    df.to_csv('data.csv', index=False)\n",
        "    return df\n",
        "\n",
        "# Execute the function and print the first few rows of the dataframe\n",
        "df_optimized = scrape_data()\n",
        "print(df_optimized.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690b9d10",
      "metadata": {
        "id": "690b9d10",
        "outputId": "8a719ff0-c48e-4821-bbae-cbe93a20b090"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hash</th>\n",
              "      <th>Method</th>\n",
              "      <th>Block</th>\n",
              "      <th>Age</th>\n",
              "      <th>From</th>\n",
              "      <th>To</th>\n",
              "      <th>Value</th>\n",
              "      <th>TxnFee</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0xfe2d690b99d54fd95ec62878169fa1bcf2162f4de09c...</td>\n",
              "      <td>Sell To Uniswap</td>\n",
              "      <td>19356643</td>\n",
              "      <td>2024-03-03 19:11:59</td>\n",
              "      <td>1709493119</td>\n",
              "      <td></td>\n",
              "      <td>0x: Exchange Proxy</td>\n",
              "      <td>0.014403182 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0xe33896e4a5bafa442b90f0d7235bf42380ba62ff1f82...</td>\n",
              "      <td>Sell To Uniswap</td>\n",
              "      <td>19356643</td>\n",
              "      <td>2024-03-03 19:11:59</td>\n",
              "      <td>1709493119</td>\n",
              "      <td></td>\n",
              "      <td>0x: Exchange Proxy</td>\n",
              "      <td>0.018443724 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0xe3064529e5983ca98f9898636c5ec81f9f68bf3b195c...</td>\n",
              "      <td>Sell To Uniswap</td>\n",
              "      <td>19356643</td>\n",
              "      <td>2024-03-03 19:11:59</td>\n",
              "      <td>1709493119</td>\n",
              "      <td></td>\n",
              "      <td>0x: Exchange Proxy</td>\n",
              "      <td>1.352960825 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0xc9c806e8554527c51796db3cf814c7a8584ca04b75fe...</td>\n",
              "      <td>Approve</td>\n",
              "      <td>19356643</td>\n",
              "      <td>2024-03-03 19:11:59</td>\n",
              "      <td>1709493119</td>\n",
              "      <td></td>\n",
              "      <td>PulsePad: PLSPAD Token</td>\n",
              "      <td>0 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x5b9815d0ac6885b604b69a37f15d0f4746d187c22c03...</td>\n",
              "      <td>Multiplex Multi ...</td>\n",
              "      <td>19356643</td>\n",
              "      <td>2024-03-03 19:11:59</td>\n",
              "      <td>1709493119</td>\n",
              "      <td></td>\n",
              "      <td>0x: Exchange Proxy</td>\n",
              "      <td>0 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>0x0e4e8469319a32e232128038cc481b4061c8ce29a893...</td>\n",
              "      <td>Execute</td>\n",
              "      <td>19356634</td>\n",
              "      <td>2024-03-03 19:09:59</td>\n",
              "      <td>1709492999</td>\n",
              "      <td></td>\n",
              "      <td>Uniswap: Universal Router</td>\n",
              "      <td>0 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>0x43cfcfe5bddc1f80bb09b2f0cb85e6baa1f0a6cce4c8...</td>\n",
              "      <td>Execute</td>\n",
              "      <td>19356634</td>\n",
              "      <td>2024-03-03 19:09:59</td>\n",
              "      <td>1709492999</td>\n",
              "      <td></td>\n",
              "      <td>Uniswap: Universal Router</td>\n",
              "      <td>0.29 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>0x87f56a5c67253684dfa8e09611509b401f95ad65bfee...</td>\n",
              "      <td>Execute</td>\n",
              "      <td>19356634</td>\n",
              "      <td>2024-03-03 19:09:59</td>\n",
              "      <td>1709492999</td>\n",
              "      <td></td>\n",
              "      <td>Uniswap: Universal Router</td>\n",
              "      <td>0 ETH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>0xe88c2c159ab64fa0644fad7d8b6572a9658df329c6b1...</td>\n",
              "      <td>0x2b603313</td>\n",
              "      <td>19356634</td>\n",
              "      <td>2024-03-03 19:09:59</td>\n",
              "      <td>1709492999</td>\n",
              "      <td></td>\n",
              "      <td>MEV Bot: 0x6b7...A80</td>\n",
              "      <td>218 wei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>0xd5fc5f69b174f3ef48cc0abf870fb4a6d4ad4477640e...</td>\n",
              "      <td>0x0162e2d0</td>\n",
              "      <td>19356634</td>\n",
              "      <td>2024-03-03 19:09:59</td>\n",
              "      <td>1709492999</td>\n",
              "      <td></td>\n",
              "      <td>Banana Gun: Router 2</td>\n",
              "      <td>0.2 ETH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1363 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Hash               Method  \\\n",
              "0     0xfe2d690b99d54fd95ec62878169fa1bcf2162f4de09c...      Sell To Uniswap   \n",
              "1     0xe33896e4a5bafa442b90f0d7235bf42380ba62ff1f82...      Sell To Uniswap   \n",
              "2     0xe3064529e5983ca98f9898636c5ec81f9f68bf3b195c...      Sell To Uniswap   \n",
              "3     0xc9c806e8554527c51796db3cf814c7a8584ca04b75fe...              Approve   \n",
              "4     0x5b9815d0ac6885b604b69a37f15d0f4746d187c22c03...  Multiplex Multi ...   \n",
              "...                                                 ...                  ...   \n",
              "1358  0x0e4e8469319a32e232128038cc481b4061c8ce29a893...              Execute   \n",
              "1359  0x43cfcfe5bddc1f80bb09b2f0cb85e6baa1f0a6cce4c8...              Execute   \n",
              "1360  0x87f56a5c67253684dfa8e09611509b401f95ad65bfee...              Execute   \n",
              "1361  0xe88c2c159ab64fa0644fad7d8b6572a9658df329c6b1...           0x2b603313   \n",
              "1362  0xd5fc5f69b174f3ef48cc0abf870fb4a6d4ad4477640e...           0x0162e2d0   \n",
              "\n",
              "         Block                  Age        From To                      Value  \\\n",
              "0     19356643  2024-03-03 19:11:59  1709493119            0x: Exchange Proxy   \n",
              "1     19356643  2024-03-03 19:11:59  1709493119            0x: Exchange Proxy   \n",
              "2     19356643  2024-03-03 19:11:59  1709493119            0x: Exchange Proxy   \n",
              "3     19356643  2024-03-03 19:11:59  1709493119        PulsePad: PLSPAD Token   \n",
              "4     19356643  2024-03-03 19:11:59  1709493119            0x: Exchange Proxy   \n",
              "...        ...                  ...         ... ..                        ...   \n",
              "1358  19356634  2024-03-03 19:09:59  1709492999     Uniswap: Universal Router   \n",
              "1359  19356634  2024-03-03 19:09:59  1709492999     Uniswap: Universal Router   \n",
              "1360  19356634  2024-03-03 19:09:59  1709492999     Uniswap: Universal Router   \n",
              "1361  19356634  2024-03-03 19:09:59  1709492999          MEV Bot: 0x6b7...A80   \n",
              "1362  19356634  2024-03-03 19:09:59  1709492999          Banana Gun: Router 2   \n",
              "\n",
              "               TxnFee  \n",
              "0     0.014403182 ETH  \n",
              "1     0.018443724 ETH  \n",
              "2     1.352960825 ETH  \n",
              "3               0 ETH  \n",
              "4               0 ETH  \n",
              "...               ...  \n",
              "1358            0 ETH  \n",
              "1359         0.29 ETH  \n",
              "1360            0 ETH  \n",
              "1361          218 wei  \n",
              "1362          0.2 ETH  \n",
              "\n",
              "[1363 rows x 8 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fcf9846",
      "metadata": {
        "id": "7fcf9846"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7113f65",
      "metadata": {
        "id": "a7113f65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6a013b104d142cfc",
      "metadata": {
        "id": "6a013b104d142cfc"
      },
      "source": [
        "## Data Analysis\n",
        "\n",
        "Now that we have collected the transaction data from Etherscan, the next step is to perform conduct an initial analysis. This task will involve the following steps:\n",
        "\n",
        "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
        "\n",
        "2. **Data Cleaning**: Clean the data by converting data types, removing any irrelevant information, and handling **duplicate** values.\n",
        "\n",
        "3. **Statistical Analysis**: Calculate the mean and standard deviation of the population. Evaluate these statistics to understand the distribution of transaction values. The analysis and plotting will be on **Txn Fee** and **Value**.\n",
        "\n",
        "4. **Visualization**: This phase involves the creation of visual representations to aid in the analysis of transaction values. The visualizations include:\n",
        "    - A histogram for each data column, which provides a visual representation of the data distribution. The selection of bin size is crucial and should be based on the data's characteristics to ensure accurate representation. Provide an explanation on the bin size selection!\n",
        "    - A normal distribution plot fitted alongside the histogram to compare the empirical distribution of the data with the theoretical normal distribution.\n",
        "    - A box plot and a violin plot to identify outliers and provide a comprehensive view of the data's distribution.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "The project aims to deliver the following deliverables:\n",
        "\n",
        "- A refined pandas DataFrame containing the transaction data, which has undergone thorough cleaning and is ready for analysis.\n",
        "- A simple statistical analysis evaluating the population statistics, offering insights into the distribution of transaction values and fees.\n",
        "- A set of visualizations showcasing the distribution of transaction values for the population. These visualizations include histograms, normal distribution plots, box plots, and violin plots, each serving a specific purpose in the analysis.\n",
        "\n",
        "### Getting Started\n",
        "\n",
        "The project starts with the importing of transaction data into a pandas DataFrame, setting the stage for data manipulation and analysis. Subsequent steps involve the cleaning of the data to ensure its quality and reliability. Followed by the calculation of population statistics. Finally, a series of visualizations are created to visually analyze the distribution of transaction values and fees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1199b5c8",
      "metadata": {
        "id": "1199b5c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f481b11a08d876b6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-25T14:02:12.152030482Z",
          "start_time": "2024-02-25T14:02:12.101846096Z"
        },
        "id": "f481b11a08d876b6"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87030e5e0b4fe1e6",
      "metadata": {
        "id": "87030e5e0b4fe1e6"
      },
      "source": [
        "## Data Sampling and Analysis\n",
        "\n",
        "In this section, we will delve into the process of data sampling and perform an initial analysis on the transaction data we have collected. Our objective is to understand the distribution of transaction values by sampling the data and comparing the sample statistics with the population statistics.\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
        "\n",
        "2. **Data Cleaning**: Clean the data by handling missing values, converting data types, and removing any irrelevant information.\n",
        "\n",
        "3. **Simple Random Sampling (SRS)**: Create a sample from the dataset using a simple random sampling method. This involves randomly selecting a subset of the data without regard to any specific characteristics of the data.\n",
        "\n",
        "4. **Stratified Sampling**: Create another sample from the dataset using a stratified sampling method. This involves dividing the data into strata based on a specific characteristic (e.g., transaction value) and then randomly selecting samples from each stratum. Explain what you have stratified the data by and why you chose this column.\n",
        "\n",
        "5. **Statistical Analysis**: Calculate the mean and standard deviation of the samples and the population. Compare these statistics to understand the distribution of transaction values.\n",
        "\n",
        "6. **Visualization**: Plot the distribution of transaction values and fees for both the samples and the population to visually compare their distributions.\n",
        "\n",
        "### Considerations\n",
        "\n",
        "- **Sample Size**: The size of the sample should be large enough to represent the population accurately but not so large that it becomes impractical to analyze.\n",
        "- **Sampling Method**: Choose the appropriate sampling method based on the characteristics of the data and the research question.\n",
        "\n",
        "Explain the above considerations in your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6becd41f9b2393",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-27T19:36:26.333480965Z",
          "start_time": "2024-02-27T19:36:26.324023052Z"
        },
        "id": "4f6becd41f9b2393"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}